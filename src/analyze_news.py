"""åˆ†ææ–°é—»æ¨¡å— - è¯»å– news_raw.jsonï¼Œè°ƒç”¨ worker_simple åˆ†æ"""

import asyncio
import json
from datetime import datetime, timezone, timedelta
from pathlib import Path
from loguru import logger

from src.models import NewsItem
from src.config import settings
from src.worker_simple import (
    DATA_DIR, ARCHIVE_DIR,
    archive_data, load_history, format_history_context,
    enrich_sectors_with_etfs, save_news, build_sector_trends, update_review,
)
from src.analyzers.realtime import analyze
from src.notify import send_wechat_message, format_analysis_message


def load_news_raw() -> tuple[list[NewsItem], dict]:
    """ä» news_raw.json åŠ è½½æ–°é—»"""
    raw_file = DATA_DIR / "news_raw.json"
    if not raw_file.exists():
        logger.warning("news_raw.json ä¸å­˜åœ¨")
        return [], {}

    data = json.loads(raw_file.read_text())
    items = []
    for item in data.get("items", []):
        news_item = NewsItem(
            title=item["title"],
            source=item["source"],
            url=item.get("url", ""),
        )
        if item.get("published_at"):
            news_item.published_at = datetime.fromisoformat(item["published_at"])
        items.append(news_item)

    return items, data.get("source_stats", {})


async def run():
    """è¿è¡Œåˆ†æ"""
    logger.info("=" * 50)
    logger.info("å¼€å§‹åˆ†ææ–°é—»")
    logger.info("=" * 50)

    beijing_tz = timezone(timedelta(hours=8))

    # åŠ è½½æ–°é—»
    items, source_stats = load_news_raw()
    if len(items) < 20:
        logger.warning(f"æ–°é—»ä¸è¶³ ({len(items)} < 20)")
        return

    logger.info(f"åŠ è½½ {len(items)} æ¡æ–°é—»")

    # å½’æ¡£æ—§æ•°æ®
    archive_data(beijing_tz)

    # åŠ è½½å†å²
    history = load_history(days=7)
    history_context = format_history_context(history)
    if history_context:
        logger.info(f"ğŸ“œ å†å²ä¸Šä¸‹æ–‡:\n{history_context}")

    # è¯»å–æ¿å—åˆ—è¡¨
    master_file = Path(__file__).parent.parent / "config" / "etf_master.json"
    sector_list = None
    if master_file.exists():
        master = json.loads(master_file.read_text())
        sector_list = master.get("sector_list", [])

    # AI åˆ†æ
    logger.info("AI åˆ†æä¸­...")
    result = await analyze(items, sector_list=sector_list, history_context=history_context)

    if not result or not result.get("sectors"):
        logger.error("åˆ†æå¤±è´¥")
        return

    logger.info(f"åˆ†æå®Œæˆ: {len(result['sectors'])} ä¸ªæ¿å—")

    # åŒ¹é… ETF
    await enrich_sectors_with_etfs(result)

    # æ„å»º7æ—¥è¶‹åŠ¿
    sector_trends = build_sector_trends(history, result.get("sectors", []))
    logger.info(f"æ„å»ºè¶‹åŠ¿: {len(sector_trends)} ä¸ªæ¿å—")

    # ä¿¡å·å¤ç›˜
    review = await update_review(result, beijing_tz)

    # è¿‡çƒ­é¢„è­¦ï¼ˆP1ï¼‰ï¼šåŸºäºçƒ­åº¦ã€æ–¹å‘ã€ç½®ä¿¡åº¦çš„è½»é‡è§„åˆ™
    overheat = None
    try:
        sectors = result.get("sectors", [])
        hot = [
            s for s in sectors
            if s.get("direction") == "åˆ©å¥½"
            and s.get("heat", 0) >= 4
            and s.get("confidence", 0) >= 80
        ]
        if len(hot) >= 3:
            overheat = {
                "level": "è¿‡çƒ­",
                "note": "é«˜çƒ­åº¦æ¿å—è¿‡å¤šï¼Œæ³¨æ„è¿½é«˜é£é™©",
                "count": len(hot),
            }
        elif len(hot) == 2:
            overheat = {
                "level": "åçƒ­",
                "note": "çƒ­ç‚¹é›†ä¸­ï¼Œæ³¨æ„é«˜ä½æ³¢åŠ¨",
                "count": len(hot),
            }
    except Exception:
        overheat = None

    # ä¿å­˜ç»“æœ
    output = {
        "result": result,
        "sector_trends": sector_trends,
        "review": review,
        "overheat": overheat,
        "updated_at": datetime.now(beijing_tz).isoformat(),
        "news_count": len(items),
        "source_stats": source_stats,
    }
    output_file = DATA_DIR / "latest.json"
    output_file.write_text(json.dumps(output, ensure_ascii=False, indent=2))
    logger.info(f"ä¿å­˜: {output_file}")

    # ä¿å­˜æ–°é—»åˆ—è¡¨
    await save_news(items, beijing_tz)

    # ä¼ä¸šå¾®ä¿¡æ¨é€
    if settings.wechat_webhook_url:
        logger.info("å‘é€ä¼ä¸šå¾®ä¿¡æ¨é€...")
        message = format_analysis_message(output)
        await send_wechat_message(settings.wechat_webhook_url, message)

    logger.info("åˆ†æå®Œæˆ")


if __name__ == "__main__":
    asyncio.run(run())
